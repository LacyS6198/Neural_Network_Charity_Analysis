{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Data for a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"Resources/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0              T10       Independent          C1000    ProductDev   \n",
       "1               T3       Independent          C2000  Preservation   \n",
       "2               T5  CompanySponsored          C3000    ProductDev   \n",
       "3               T3  CompanySponsored          C2000  Preservation   \n",
       "4               T3       Independent          C1000     Heathcare   \n",
       "\n",
       "   ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "0   Association       1              0                      N     5000   \n",
       "1  Co-operative       1         1-9999                      N   108590   \n",
       "2   Association       1              0                      N     5000   \n",
       "3         Trust       1    10000-24999                      N     6692   \n",
       "4         Trust       1  100000-499999                      N   142590   \n",
       "\n",
       "   IS_SUCCESSFUL  \n",
       "0              1  \n",
       "1              1  \n",
       "2              0  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df = application_df.drop(columns=[\"EIN\", \"NAME\"])\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE            17\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION              71\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "application_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T25        3\n",
       "T14        3\n",
       "T29        2\n",
       "T15        2\n",
       "T17        1\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "application_counts = application_df.APPLICATION_TYPE.value_counts()\n",
    "application_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the value counts of APPLICATION_TYPE\n",
    "application_counts.value_counts().plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "T8         737\n",
       "T7         725\n",
       "T10        528\n",
       "Other      276\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which values to replace if counts are less than ...?\n",
    "replace_application = list(application_counts[application_counts < 500].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in replace_application:\n",
    "    application_df.APPLICATION_TYPE = application_df.APPLICATION_TYPE.replace(app,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df.APPLICATION_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "         ...  \n",
       "C4120        1\n",
       "C8210        1\n",
       "C2561        1\n",
       "C4500        1\n",
       "C2150        1\n",
       "Name: CLASSIFICATION, Length: 71, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "classification_counts = application_df.CLASSIFICATION.value_counts()\n",
    "classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the value counts of CLASSIFICATION\n",
    "classification_counts.value_counts().plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "Other     2261\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which values to replace if counts are less than ..?\n",
    "replace_class = list(classification_counts[classification_counts < 1000].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in replace_class:\n",
    "    application_df.CLASSIFICATION = application_df.CLASSIFICATION.replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df.CLASSIFICATION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['APPLICATION_TYPE',\n",
       " 'AFFILIATION',\n",
       " 'CLASSIFICATION',\n",
       " 'USE_CASE',\n",
       " 'ORGANIZATION',\n",
       " 'INCOME_AMT',\n",
       " 'SPECIAL_CONSIDERATIONS']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate our categorical variable lists\n",
    "application_cat = application_df.dtypes[application_df.dtypes == \"object\"].index.tolist()\n",
    "application_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>APPLICATION_TYPE_T8</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPLICATION_TYPE_Other  APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  \\\n",
       "0                     0.0                   1.0                   0.0   \n",
       "1                     0.0                   0.0                   0.0   \n",
       "2                     0.0                   0.0                   0.0   \n",
       "3                     0.0                   0.0                   0.0   \n",
       "4                     0.0                   0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  1.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  1.0   \n",
       "3                  1.0                  0.0                  0.0   \n",
       "4                  1.0                  0.0                  0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  APPLICATION_TYPE_T8  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   AFFILIATION_CompanySponsored  ...  INCOME_AMT_1-9999  \\\n",
       "0                           0.0  ...                0.0   \n",
       "1                           0.0  ...                1.0   \n",
       "2                           1.0  ...                0.0   \n",
       "3                           1.0  ...                0.0   \n",
       "4                           0.0  ...                0.0   \n",
       "\n",
       "   INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
       "0                     0.0                       0.0                 0.0   \n",
       "1                     0.0                       0.0                 0.0   \n",
       "2                     0.0                       0.0                 0.0   \n",
       "3                     1.0                       0.0                 0.0   \n",
       "4                     0.0                       1.0                 0.0   \n",
       "\n",
       "   INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
       "0               0.0                     0.0              0.0   \n",
       "1               0.0                     0.0              0.0   \n",
       "2               0.0                     0.0              0.0   \n",
       "3               0.0                     0.0              0.0   \n",
       "4               0.0                     0.0              0.0   \n",
       "\n",
       "   INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                0.0                       1.0                       0.0  \n",
       "1                0.0                       1.0                       0.0  \n",
       "2                0.0                       1.0                       0.0  \n",
       "3                0.0                       1.0                       0.0  \n",
       "4                0.0                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(application_df[application_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(application_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lacys\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0       1     5000              1                     0.0   \n",
       "1       1   108590              1                     0.0   \n",
       "2       1     5000              0                     0.0   \n",
       "3       1     6692              1                     0.0   \n",
       "4       1   142590              1                     0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
       "0                   1.0                   0.0                  0.0   \n",
       "1                   0.0                   0.0                  1.0   \n",
       "2                   0.0                   0.0                  0.0   \n",
       "3                   0.0                   0.0                  1.0   \n",
       "4                   0.0                   0.0                  1.0   \n",
       "\n",
       "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
       "0                  0.0                  0.0                  0.0  ...   \n",
       "1                  0.0                  0.0                  0.0  ...   \n",
       "2                  0.0                  1.0                  0.0  ...   \n",
       "3                  0.0                  0.0                  0.0  ...   \n",
       "4                  0.0                  0.0                  0.0  ...   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                0.0                     0.0                       0.0   \n",
       "1                1.0                     0.0                       0.0   \n",
       "2                0.0                     0.0                       0.0   \n",
       "3                0.0                     1.0                       0.0   \n",
       "4                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "application_df = application_df.merge(encode_df,left_index=True, right_index=True)\n",
    "application_df = application_df.drop(application_cat,1)\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lacys\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = application_df[\"IS_SUCCESSFUL\"].values\n",
    "X = application_df.drop([\"IS_SUCCESSFUL\"],1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverable 3 - Optimize Attempt 1:  Add a third hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 80)                3520      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                2430      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 15)                465       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,431\n",
      "Trainable params: 6,431\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 80\n",
    "hidden_nodes_layer2 = 30\n",
    "hidden_nodes_layer3 = 15\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the checkpoint path and filenames\n",
    "os.makedirs(\"checkpoints_optimization_a1/\", exist_ok=True)\n",
    "checkpoint_path = \"checkpoints_optimization_a1/weights.{epoch:02d}hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "804/804 [==============================] - 1s 678us/step - loss: 0.5733 - accuracy: 0.7201\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 1s 653us/step - loss: 0.5548 - accuracy: 0.7311\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 1s 674us/step - loss: 0.5520 - accuracy: 0.7311\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 1s 697us/step - loss: 0.5500 - accuracy: 0.7333\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 1s 698us/step - loss: 0.5487 - accuracy: 0.7333\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 1s 689us/step - loss: 0.5478 - accuracy: 0.7322\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 1s 700us/step - loss: 0.5468 - accuracy: 0.7335\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 1s 807us/step - loss: 0.5467 - accuracy: 0.7338\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 1s 719us/step - loss: 0.5463 - accuracy: 0.7364\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 1s 783us/step - loss: 0.5454 - accuracy: 0.7360\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 1s 726us/step - loss: 0.5451 - accuracy: 0.7362\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 1s 721us/step - loss: 0.5452 - accuracy: 0.7361\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 1s 745us/step - loss: 0.5450 - accuracy: 0.7358\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 1s 685us/step - loss: 0.5444 - accuracy: 0.7373\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 1s 714us/step - loss: 0.5442 - accuracy: 0.7357\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 1s 691us/step - loss: 0.5437 - accuracy: 0.7367\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 1s 722us/step - loss: 0.5436 - accuracy: 0.7371\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 1s 777us/step - loss: 0.5429 - accuracy: 0.7370\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 1s 709us/step - loss: 0.5426 - accuracy: 0.7369\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 1s 750us/step - loss: 0.5428 - accuracy: 0.7390\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 1s 745us/step - loss: 0.5424 - accuracy: 0.7378\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 1s 728us/step - loss: 0.5422 - accuracy: 0.7376\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 1s 731us/step - loss: 0.5416 - accuracy: 0.7371\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 1s 703us/step - loss: 0.5419 - accuracy: 0.7371\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 1s 733us/step - loss: 0.5413 - accuracy: 0.7378\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 1s 714us/step - loss: 0.5414 - accuracy: 0.7379\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 1s 771us/step - loss: 0.5412 - accuracy: 0.7385\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 1s 765us/step - loss: 0.5411 - accuracy: 0.7380\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 1s 700us/step - loss: 0.5413 - accuracy: 0.7379\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 1s 767us/step - loss: 0.5406 - accuracy: 0.7393\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 1s 710us/step - loss: 0.5406 - accuracy: 0.7386\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 1s 762us/step - loss: 0.5401 - accuracy: 0.7386\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 1s 719us/step - loss: 0.5404 - accuracy: 0.7388\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 1s 734us/step - loss: 0.5402 - accuracy: 0.7389\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 1s 775us/step - loss: 0.5395 - accuracy: 0.7393\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 1s 748us/step - loss: 0.5402 - accuracy: 0.7395\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 1s 803us/step - loss: 0.5398 - accuracy: 0.7392\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 1s 804us/step - loss: 0.5398 - accuracy: 0.7393\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 1s 767us/step - loss: 0.5397 - accuracy: 0.7390\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 1s 780us/step - loss: 0.5393 - accuracy: 0.7387\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 1s 731us/step - loss: 0.5392 - accuracy: 0.7406\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 1s 813us/step - loss: 0.5395 - accuracy: 0.7392\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 1s 798us/step - loss: 0.5394 - accuracy: 0.7400\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 1s 716us/step - loss: 0.5387 - accuracy: 0.7400\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 1s 775us/step - loss: 0.5393 - accuracy: 0.7399\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 1s 741us/step - loss: 0.5387 - accuracy: 0.7399\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 1s 803us/step - loss: 0.5385 - accuracy: 0.7408\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 1s 800us/step - loss: 0.5380 - accuracy: 0.7399\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 1s 732us/step - loss: 0.5384 - accuracy: 0.7399\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 1s 789us/step - loss: 0.5382 - accuracy: 0.7397\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 1s 770us/step - loss: 0.5378 - accuracy: 0.7393\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 1s 824us/step - loss: 0.5380 - accuracy: 0.7396\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 1s 800us/step - loss: 0.5380 - accuracy: 0.7404\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 1s 757us/step - loss: 0.5382 - accuracy: 0.7398\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 1s 768us/step - loss: 0.5376 - accuracy: 0.7399\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 1s 773us/step - loss: 0.5376 - accuracy: 0.7394\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 1s 805us/step - loss: 0.5383 - accuracy: 0.7399\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 1s 743us/step - loss: 0.5376 - accuracy: 0.7392\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 1s 699us/step - loss: 0.5373 - accuracy: 0.7404\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 1s 729us/step - loss: 0.5374 - accuracy: 0.7398\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 1s 760us/step - loss: 0.5374 - accuracy: 0.7400\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 1s 837us/step - loss: 0.5375 - accuracy: 0.7395\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 1s 762us/step - loss: 0.5366 - accuracy: 0.7396\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 1s 743us/step - loss: 0.5374 - accuracy: 0.7406\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 1s 762us/step - loss: 0.5367 - accuracy: 0.7395\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 1s 777us/step - loss: 0.5372 - accuracy: 0.7393\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 1s 797us/step - loss: 0.5367 - accuracy: 0.7398\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 1s 739us/step - loss: 0.5366 - accuracy: 0.7405\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 1s 717us/step - loss: 0.5369 - accuracy: 0.7399\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 1s 754us/step - loss: 0.5370 - accuracy: 0.7400\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 1s 743us/step - loss: 0.5368 - accuracy: 0.7406\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 1s 851us/step - loss: 0.5368 - accuracy: 0.7398\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 1s 718us/step - loss: 0.5369 - accuracy: 0.7407\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 1s 712us/step - loss: 0.5362 - accuracy: 0.7397\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 1s 752us/step - loss: 0.5367 - accuracy: 0.7405\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 1s 779us/step - loss: 0.5361 - accuracy: 0.7408\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 1s 889us/step - loss: 0.5367 - accuracy: 0.7406\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 1s 739us/step - loss: 0.5361 - accuracy: 0.7404\n",
      "Epoch 79/100\n",
      "804/804 [==============================] - 1s 740us/step - loss: 0.5358 - accuracy: 0.7401\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 1s 738us/step - loss: 0.5363 - accuracy: 0.7400\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 1s 827us/step - loss: 0.5360 - accuracy: 0.7404\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 1s 733us/step - loss: 0.5363 - accuracy: 0.7404\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 1s 706us/step - loss: 0.5361 - accuracy: 0.7409\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 1s 728us/step - loss: 0.5361 - accuracy: 0.7403\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 1s 781us/step - loss: 0.5361 - accuracy: 0.7404\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 1s 840us/step - loss: 0.5355 - accuracy: 0.7409\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 1s 761us/step - loss: 0.5359 - accuracy: 0.7403\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 1s 774us/step - loss: 0.5359 - accuracy: 0.7402\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 1s 830us/step - loss: 0.5354 - accuracy: 0.7414\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 1s 890us/step - loss: 0.5353 - accuracy: 0.7405\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7407\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 1s 843us/step - loss: 0.5356 - accuracy: 0.7400\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 1s 810us/step - loss: 0.5356 - accuracy: 0.7403\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 1s 806us/step - loss: 0.5354 - accuracy: 0.7405\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 1s 809us/step - loss: 0.5355 - accuracy: 0.7410\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 1s 763us/step - loss: 0.5360 - accuracy: 0.7397\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 1s 820us/step - loss: 0.5354 - accuracy: 0.7401\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 1s 837us/step - loss: 0.5351 - accuracy: 0.7411\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 1s 772us/step - loss: 0.5354 - accuracy: 0.7404\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 1s 771us/step - loss: 0.5354 - accuracy: 0.7406\n"
     ]
    }
   ],
   "source": [
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=0,\n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch',\n",
    "    period=5)\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5558 - accuracy: 0.7277 - 255ms/epoch - 953us/step\n",
      "Loss: 0.5557719469070435, Accuracy: 0.7276967763900757\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverable 3 - Optimize Attempt 2:  Use Leaky Relu instead of ReLu & Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 80)                3520      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 30)                2430      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 15)                465       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,431\n",
      "Trainable params: 6,431\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 80\n",
    "hidden_nodes_layer2 = 30\n",
    "hidden_nodes_layer3 = 15\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"leaky_relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"leaky_relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"leaky_relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"leaky_relu\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the checkpoint path and filenames\n",
    "os.makedirs(\"checkpoints_optimization_a2/\", exist_ok=True)\n",
    "checkpoint_path = \"checkpoints_optimization_a2/weights.{epoch:02d}hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "804/804 [==============================] - 1s 886us/step - loss: 1.1055 - accuracy: 0.6907\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 1s 845us/step - loss: 0.8782 - accuracy: 0.7167\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 1s 783us/step - loss: 0.8248 - accuracy: 0.7181\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 1s 810us/step - loss: 0.8505 - accuracy: 0.7135\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 1s 895us/step - loss: 0.8259 - accuracy: 0.7074\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 1s 896us/step - loss: 0.8049 - accuracy: 0.7181\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 1s 937us/step - loss: 0.8201 - accuracy: 0.7204\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 1s 810us/step - loss: 0.6657 - accuracy: 0.7217\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 1s 814us/step - loss: 0.6742 - accuracy: 0.7165\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.6712 - accuracy: 0.7287\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.6712 - accuracy: 0.7276\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.8676 - accuracy: 0.7121\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.8589 - accuracy: 0.7168\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.8639 - accuracy: 0.7126\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.8535 - accuracy: 0.7167\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.8444 - accuracy: 0.7165\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.7162 - accuracy: 0.7171\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 1s 931us/step - loss: 0.5848 - accuracy: 0.7320\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 1s 921us/step - loss: 0.6297 - accuracy: 0.7248\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 1s 924us/step - loss: 0.5932 - accuracy: 0.7292\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5824 - accuracy: 0.7283\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 1s 925us/step - loss: 0.5876 - accuracy: 0.7293\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 1s 928us/step - loss: 0.5811 - accuracy: 0.7322\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 1s 935us/step - loss: 0.5877 - accuracy: 0.7293\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 1s 949us/step - loss: 0.5964 - accuracy: 0.7300\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 1s 909us/step - loss: 0.5999 - accuracy: 0.7261\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5915 - accuracy: 0.7280\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 1s 934us/step - loss: 0.5955 - accuracy: 0.7248\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 1s 917us/step - loss: 0.5904 - accuracy: 0.7313\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 1s 863us/step - loss: 0.5936 - accuracy: 0.7296\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 1s 924us/step - loss: 0.6003 - accuracy: 0.7163\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 1s 788us/step - loss: 0.5761 - accuracy: 0.7308\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 1s 758us/step - loss: 0.5772 - accuracy: 0.7294\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 1s 799us/step - loss: 0.5716 - accuracy: 0.7264\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 1s 793us/step - loss: 0.5758 - accuracy: 0.7303\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 1s 912us/step - loss: 0.5745 - accuracy: 0.7276\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 1s 803us/step - loss: 0.6081 - accuracy: 0.7200\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 1s 776us/step - loss: 0.5831 - accuracy: 0.7287\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 1s 806us/step - loss: 0.5740 - accuracy: 0.7327\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 1s 836us/step - loss: 0.5693 - accuracy: 0.7319\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 1s 753us/step - loss: 0.5649 - accuracy: 0.7335\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 1s 782us/step - loss: 0.5679 - accuracy: 0.7349\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 1s 915us/step - loss: 0.5689 - accuracy: 0.7328\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 1s 808us/step - loss: 0.5739 - accuracy: 0.7338\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 1s 902us/step - loss: 0.6156 - accuracy: 0.7311\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 1s 840us/step - loss: 0.5718 - accuracy: 0.7332\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 1s 925us/step - loss: 0.5792 - accuracy: 0.7339\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 1s 902us/step - loss: 0.5734 - accuracy: 0.7277\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 1s 827us/step - loss: 0.5740 - accuracy: 0.7325\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 1s 836us/step - loss: 0.5707 - accuracy: 0.7351\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 1s 914us/step - loss: 0.5799 - accuracy: 0.7311\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 1s 904us/step - loss: 0.5769 - accuracy: 0.7319\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5838 - accuracy: 0.7307\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5849 - accuracy: 0.7269\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5722 - accuracy: 0.7301\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 1s 988us/step - loss: 0.5789 - accuracy: 0.7337\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5722 - accuracy: 0.7318\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 1s 917us/step - loss: 0.5741 - accuracy: 0.7298\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 1s 888us/step - loss: 0.5720 - accuracy: 0.7315\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 1s 915us/step - loss: 0.5632 - accuracy: 0.7343\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5768 - accuracy: 0.7231\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 1s 939us/step - loss: 0.5709 - accuracy: 0.7287\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 1s 906us/step - loss: 0.5704 - accuracy: 0.7345\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 1s 900us/step - loss: 0.5641 - accuracy: 0.7350\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 1s 930us/step - loss: 0.5635 - accuracy: 0.7336\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 1s 915us/step - loss: 0.5686 - accuracy: 0.7350\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5675 - accuracy: 0.7318\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 1s 878us/step - loss: 0.5697 - accuracy: 0.7346\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 1s 885us/step - loss: 0.5700 - accuracy: 0.7337\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 1s 917us/step - loss: 0.5727 - accuracy: 0.7291\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 1s 972us/step - loss: 0.5791 - accuracy: 0.7336\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 1s 869us/step - loss: 0.5672 - accuracy: 0.7334\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 1s 839us/step - loss: 0.5685 - accuracy: 0.7353\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 1s 859us/step - loss: 0.5849 - accuracy: 0.7215\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 1s 820us/step - loss: 0.5685 - accuracy: 0.7341\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 1s 787us/step - loss: 0.5677 - accuracy: 0.7361\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 1s 824us/step - loss: 0.5762 - accuracy: 0.7305\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 1s 850us/step - loss: 0.5658 - accuracy: 0.7335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "804/804 [==============================] - 1s 801us/step - loss: 0.5608 - accuracy: 0.7341\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 1s 794us/step - loss: 0.5636 - accuracy: 0.7350\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 1s 781us/step - loss: 0.5652 - accuracy: 0.7344\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 1s 883us/step - loss: 0.5640 - accuracy: 0.7345\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 1s 794us/step - loss: 0.5616 - accuracy: 0.7364\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 1s 775us/step - loss: 0.5663 - accuracy: 0.7335\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 1s 795us/step - loss: 0.5731 - accuracy: 0.7296\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 1s 807us/step - loss: 0.5653 - accuracy: 0.7352\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 1s 905us/step - loss: 0.5683 - accuracy: 0.7340\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 1s 883us/step - loss: 0.5627 - accuracy: 0.7351\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 1s 797us/step - loss: 0.5629 - accuracy: 0.7363\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 1s 833us/step - loss: 0.5806 - accuracy: 0.7324\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5692 - accuracy: 0.7354\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 1s 922us/step - loss: 0.5615 - accuracy: 0.7359\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5609 - accuracy: 0.7352\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5634 - accuracy: 0.7354\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5635 - accuracy: 0.7365\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 1s 939us/step - loss: 0.5593 - accuracy: 0.7375\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5630 - accuracy: 0.7360\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 1s 853us/step - loss: 0.5683 - accuracy: 0.7318\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 1s 823us/step - loss: 0.5760 - accuracy: 0.7221\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 1s 848us/step - loss: 0.5605 - accuracy: 0.7341\n"
     ]
    }
   ],
   "source": [
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=0,\n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch',\n",
    "    period=5)\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5801 - accuracy: 0.7231 - 230ms/epoch - 857us/step\n",
      "Loss: 0.5801404118537903, Accuracy: 0.7231487035751343\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverable 3 - Optimize Attempt 3: categorize ASK_AMT column, use 3 hiddle layers, and LeakyRelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATUS                             2\n",
       "ASK_AMT                         8747\n",
       "IS_SUCCESSFUL                      2\n",
       "APPLICATION_TYPE_Other             2\n",
       "APPLICATION_TYPE_T10               2\n",
       "APPLICATION_TYPE_T19               2\n",
       "APPLICATION_TYPE_T3                2\n",
       "APPLICATION_TYPE_T4                2\n",
       "APPLICATION_TYPE_T5                2\n",
       "APPLICATION_TYPE_T6                2\n",
       "APPLICATION_TYPE_T7                2\n",
       "APPLICATION_TYPE_T8                2\n",
       "AFFILIATION_CompanySponsored       2\n",
       "AFFILIATION_Family/Parent          2\n",
       "AFFILIATION_Independent            2\n",
       "AFFILIATION_National               2\n",
       "AFFILIATION_Other                  2\n",
       "AFFILIATION_Regional               2\n",
       "CLASSIFICATION_C1000               2\n",
       "CLASSIFICATION_C1200               2\n",
       "CLASSIFICATION_C2000               2\n",
       "CLASSIFICATION_C2100               2\n",
       "CLASSIFICATION_C3000               2\n",
       "CLASSIFICATION_Other               2\n",
       "USE_CASE_CommunityServ             2\n",
       "USE_CASE_Heathcare                 2\n",
       "USE_CASE_Other                     2\n",
       "USE_CASE_Preservation              2\n",
       "USE_CASE_ProductDev                2\n",
       "ORGANIZATION_Association           2\n",
       "ORGANIZATION_Co-operative          2\n",
       "ORGANIZATION_Corporation           2\n",
       "ORGANIZATION_Trust                 2\n",
       "INCOME_AMT_0                       2\n",
       "INCOME_AMT_1-9999                  2\n",
       "INCOME_AMT_10000-24999             2\n",
       "INCOME_AMT_100000-499999           2\n",
       "INCOME_AMT_10M-50M                 2\n",
       "INCOME_AMT_1M-5M                   2\n",
       "INCOME_AMT_25000-99999             2\n",
       "INCOME_AMT_50M+                    2\n",
       "INCOME_AMT_5M-10M                  2\n",
       "SPECIAL_CONSIDERATIONS_N           2\n",
       "SPECIAL_CONSIDERATIONS_Y           2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000        25398\n",
       "10478           3\n",
       "15583           3\n",
       "63981           3\n",
       "6725            3\n",
       "            ...  \n",
       "5371754         1\n",
       "30060           1\n",
       "43091152        1\n",
       "18683           1\n",
       "36500179        1\n",
       "Name: ASK_AMT, Length: 8747, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ASK_AMT_counts = application_df.ASK_AMT.value_counts()\n",
    "ASK_AMT_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_group(ASK_AMT):\n",
    "    if ASK_AMT < 5000:\n",
    "        return 0\n",
    "    elif ASK_AMT < 50000:\n",
    "        return 1\n",
    "    elif ASK_AMT < 100000:\n",
    "        return 2\n",
    "    elif ASK_AMT < 250000:\n",
    "        return 3\n",
    "    elif ASK_AMT < 500000:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_df[\"ASK_AMT\"] = application_df.apply(lambda row: ask_group(row[\"ASK_AMT\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0       1        1              1                     0.0   \n",
       "1       1        3              1                     0.0   \n",
       "2       1        1              0                     0.0   \n",
       "3       1        1              1                     0.0   \n",
       "4       1        3              1                     0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
       "0                   1.0                   0.0                  0.0   \n",
       "1                   0.0                   0.0                  1.0   \n",
       "2                   0.0                   0.0                  0.0   \n",
       "3                   0.0                   0.0                  1.0   \n",
       "4                   0.0                   0.0                  1.0   \n",
       "\n",
       "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
       "0                  0.0                  0.0                  0.0  ...   \n",
       "1                  0.0                  0.0                  0.0  ...   \n",
       "2                  0.0                  1.0                  0.0  ...   \n",
       "3                  0.0                  0.0                  0.0  ...   \n",
       "4                  0.0                  0.0                  0.0  ...   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                0.0                     0.0                       0.0   \n",
       "1                1.0                     0.0                       0.0   \n",
       "2                0.0                     0.0                       0.0   \n",
       "3                0.0                     1.0                       0.0   \n",
       "4                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lacys\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = application_df[\"IS_SUCCESSFUL\"].values\n",
    "X = application_df.drop([\"IS_SUCCESSFUL\"],1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 80)                3520      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 30)                2430      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 15)                465       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,431\n",
      "Trainable params: 6,431\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 80\n",
    "hidden_nodes_layer2 = 30\n",
    "hidden_nodes_layer3 = 15\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"leaky_relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"leaky_relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"leaky_relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"leaky_relu\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the checkpoint path and filenames\n",
    "os.makedirs(\"checkpoints_optimization_a3/\", exist_ok=True)\n",
    "checkpoint_path = \"checkpoints_optimization_a3/weights.{epoch:02d}hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "804/804 [==============================] - 1s 751us/step - loss: 0.8056 - accuracy: 0.6971\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 1s 802us/step - loss: 0.7238 - accuracy: 0.7139\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 1s 825us/step - loss: 0.7038 - accuracy: 0.7160\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 1s 861us/step - loss: 0.8158 - accuracy: 0.7177\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 1s 915us/step - loss: 0.7233 - accuracy: 0.7135\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 1s 929us/step - loss: 0.6514 - accuracy: 0.7153\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 1s 940us/step - loss: 0.6302 - accuracy: 0.7262\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 1s 792us/step - loss: 0.6142 - accuracy: 0.7174\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 1s 761us/step - loss: 0.6348 - accuracy: 0.6958\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 1s 813us/step - loss: 0.6330 - accuracy: 0.7211\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 1s 842us/step - loss: 0.6411 - accuracy: 0.7254\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 1s 930us/step - loss: 0.6479 - accuracy: 0.7228\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 1s 812us/step - loss: 0.6274 - accuracy: 0.7227\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 1s 820us/step - loss: 0.6050 - accuracy: 0.7229\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 1s 804us/step - loss: 0.5921 - accuracy: 0.7223\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 1s 902us/step - loss: 0.5821 - accuracy: 0.7321\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 1s 814us/step - loss: 0.5723 - accuracy: 0.7306\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 1s 761us/step - loss: 0.5841 - accuracy: 0.7285\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 1s 773us/step - loss: 0.5852 - accuracy: 0.7271\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 1s 816us/step - loss: 0.6528 - accuracy: 0.7051\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 1s 788us/step - loss: 0.5812 - accuracy: 0.7280\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 1s 842us/step - loss: 0.5797 - accuracy: 0.7304\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 1s 936us/step - loss: 0.5754 - accuracy: 0.7303\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 1s 889us/step - loss: 0.5736 - accuracy: 0.7292\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 1s 917us/step - loss: 0.5736 - accuracy: 0.7286\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 1s 869us/step - loss: 0.5840 - accuracy: 0.7286\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 1s 812us/step - loss: 0.6224 - accuracy: 0.7114\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 1s 806us/step - loss: 0.5708 - accuracy: 0.7296\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 1s 819us/step - loss: 0.5683 - accuracy: 0.7337\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 1s 855us/step - loss: 0.5673 - accuracy: 0.7280\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 1s 900us/step - loss: 0.5737 - accuracy: 0.7244\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 1s 934us/step - loss: 0.5676 - accuracy: 0.7304\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 1s 802us/step - loss: 0.5672 - accuracy: 0.7271\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 1s 767us/step - loss: 0.5634 - accuracy: 0.7327\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 1s 749us/step - loss: 0.5827 - accuracy: 0.7281\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 1s 873us/step - loss: 0.5943 - accuracy: 0.7278\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 1s 869us/step - loss: 0.5796 - accuracy: 0.7320\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 1s 977us/step - loss: 0.5781 - accuracy: 0.7322\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 1s 978us/step - loss: 0.5822 - accuracy: 0.7280\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 1s 936us/step - loss: 0.5819 - accuracy: 0.7329\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5807 - accuracy: 0.7319\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 1s 924us/step - loss: 0.5828 - accuracy: 0.7294\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 1s 932us/step - loss: 0.5798 - accuracy: 0.7316\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 1s 911us/step - loss: 0.5820 - accuracy: 0.7299\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 1s 925us/step - loss: 0.5786 - accuracy: 0.7316\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 1s 908us/step - loss: 0.5673 - accuracy: 0.7310\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5660 - accuracy: 0.7336\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 1s 914us/step - loss: 0.5643 - accuracy: 0.7333\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 1s 904us/step - loss: 0.5635 - accuracy: 0.7314\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 1s 993us/step - loss: 0.5610 - accuracy: 0.7345\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5690 - accuracy: 0.7268\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 1s 939us/step - loss: 0.5612 - accuracy: 0.7336\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 1s 937us/step - loss: 0.5602 - accuracy: 0.7342\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 1s 908us/step - loss: 0.5740 - accuracy: 0.7313\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 1s 920us/step - loss: 0.5845 - accuracy: 0.7285\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 1s 914us/step - loss: 0.5802 - accuracy: 0.7329\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5664 - accuracy: 0.7344\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 1s 961us/step - loss: 0.5638 - accuracy: 0.7294\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 1s 952us/step - loss: 0.5889 - accuracy: 0.7303\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5717 - accuracy: 0.7333\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 1s 919us/step - loss: 0.5712 - accuracy: 0.7341\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 1s 780us/step - loss: 0.5724 - accuracy: 0.7337\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 1s 749us/step - loss: 0.5737 - accuracy: 0.7339\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 1s 739us/step - loss: 0.5829 - accuracy: 0.7309\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 1s 748us/step - loss: 0.6097 - accuracy: 0.6654\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 1s 776us/step - loss: 0.5631 - accuracy: 0.7269\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 1s 818us/step - loss: 0.5563 - accuracy: 0.7338\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 1s 820us/step - loss: 0.5594 - accuracy: 0.7327\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 1s 787us/step - loss: 0.5574 - accuracy: 0.7352\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 1s 783us/step - loss: 0.5539 - accuracy: 0.7355\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 1s 825us/step - loss: 0.5546 - accuracy: 0.7331\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 1s 885us/step - loss: 0.5574 - accuracy: 0.7335\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 1s 851us/step - loss: 0.5522 - accuracy: 0.7365\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 1s 843us/step - loss: 0.5541 - accuracy: 0.7355\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 1s 855us/step - loss: 0.5636 - accuracy: 0.7283\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 1s 866us/step - loss: 0.5658 - accuracy: 0.7317\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 1s 743us/step - loss: 0.5604 - accuracy: 0.7346\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 1s 752us/step - loss: 0.5675 - accuracy: 0.7358\n",
      "Epoch 79/100\n",
      "804/804 [==============================] - 1s 788us/step - loss: 0.5642 - accuracy: 0.7355\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 1s 808us/step - loss: 0.5531 - accuracy: 0.7353\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 1s 768us/step - loss: 0.5575 - accuracy: 0.7346\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5618 - accuracy: 0.7355\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5717 - accuracy: 0.7285\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5852 - accuracy: 0.7198\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5578 - accuracy: 0.7271\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5528 - accuracy: 0.7322\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5492 - accuracy: 0.7345\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 1s 967us/step - loss: 0.5489 - accuracy: 0.7347\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 1s 945us/step - loss: 0.5483 - accuracy: 0.7354\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 1s 955us/step - loss: 0.5530 - accuracy: 0.7341\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 1s 903us/step - loss: 0.5520 - accuracy: 0.7348\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 1s 994us/step - loss: 0.5518 - accuracy: 0.7357\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 1s 899us/step - loss: 0.5645 - accuracy: 0.7366\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 1s 910us/step - loss: 0.5667 - accuracy: 0.7322\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 1s 939us/step - loss: 0.5547 - accuracy: 0.7345\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5525 - accuracy: 0.7357\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 1s 911us/step - loss: 0.5739 - accuracy: 0.7183\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 1s 913us/step - loss: 0.5690 - accuracy: 0.7315\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 1s 891us/step - loss: 0.5644 - accuracy: 0.7292\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 1s 916us/step - loss: 0.5585 - accuracy: 0.7335\n"
     ]
    }
   ],
   "source": [
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=0,\n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch',\n",
    "    period=5)\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5756 - accuracy: 0.7238 - 263ms/epoch - 982us/step\n",
      "Loss: 0.5756166577339172, Accuracy: 0.7238484025001526\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save(\"AlphabetSoupCharity_Optimization.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
